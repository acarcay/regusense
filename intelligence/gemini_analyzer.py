"""
Gemini AI Analyst Module.

Uses Google Gemini API to verify and classify risk hits detected by the
keyword-based RiskEngine, distinguishing real legislative threats from noise.

Now includes commission member data to identify speakers and their roles,
enhancing analysis with context about who is speaking (BAÅžKAN, BAÅžKANVEKÄ°LÄ°, ÃœYE).

Author: ReguSense Team
"""

from __future__ import annotations

import json
import logging
import os
import re
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Optional

try:
    import google.generativeai as genai
except ImportError:
    genai = None  # type: ignore

from intelligence.risk_engine import RiskHit, Sector

logger = logging.getLogger(__name__)


class RiskLevel(str, Enum):
    """Risk severity classification from AI analysis."""
    
    HIGH = "HIGH"
    MEDIUM = "MEDIUM"
    LOW = "LOW"
    NOISE = "NOISE"


@dataclass
class VerifiedRisk:
    """
    AI-verified risk assessment from Gemini analysis.
    
    Enhanced with Executive-Level Strategic Insights including:
    - Business impact analysis (operational/financial consequences)
    - Compliance difficulty assessment
    - Tone analysis (speaker's stance toward sector)
    - Likelihood of becoming law
    - Speaker identification and authority level
    
    Attributes:
        original_hit: The original RiskHit from keyword matching
        is_risk: Whether this is a genuine legislative risk
        risk_level: Severity classification (HIGH/MEDIUM/LOW/NOISE)
        summary: Executive summary of the specific threat (max 2 sentences)
        business_impact: Specific operational/financial consequences
        compliance_difficulty: How hard to comply (Hard/Medium/Easy)
        actionable_insight: Step-by-step recommendation for Legal/Product teams
        tone_analysis: Speaker's stance (Hostile/Neutral/Supportive)
        likelihood: Probability of becoming law (High/Low)
        speaker_identified: Detected speaker name and role
        raw_response: Raw JSON response from Gemini (for debugging)
    """
    
    original_hit: RiskHit
    is_risk: bool = False
    risk_level: RiskLevel = RiskLevel.NOISE
    summary: str = ""
    business_impact: str = ""
    compliance_difficulty: str = ""
    actionable_insight: str = ""
    tone_analysis: str = ""
    likelihood: str = ""
    speaker_identified: str = ""
    raw_response: dict = field(default_factory=dict)
    
    def to_dict(self) -> dict:
        """Convert to dictionary for JSON serialization."""
        return {
            "sector": self.original_hit.sector.value,
            "page_number": self.original_hit.page_number,
            "is_risk": self.is_risk,
            "risk_level": self.risk_level.value,
            "summary": self.summary,
            "business_impact": self.business_impact,
            "compliance_difficulty": self.compliance_difficulty,
            "actionable_insight": self.actionable_insight,
            "tone_analysis": self.tone_analysis,
            "likelihood": self.likelihood,
            "speaker_identified": self.speaker_identified,
            "threat_keywords": {
                "sector": self.original_hit.sector_keyword,
                "threat": self.original_hit.threat_keyword,
            },
            "snippet": self.original_hit.snippet[:200] + "..." if len(self.original_hit.snippet) > 200 else self.original_hit.snippet,
        }


@dataclass
class IntelligenceReport:
    """
    Complete AI-verified intelligence report.
    
    Attributes:
        verified_risks: List of verified risk assessments
        total_hits_analyzed: Number of raw hits sent to AI
        genuine_risks: Number of hits classified as actual risks
        noise_filtered: Number of hits classified as noise
    """
    
    verified_risks: list[VerifiedRisk] = field(default_factory=list)
    total_hits_analyzed: int = 0
    
    @property
    def genuine_risks(self) -> list[VerifiedRisk]:
        """Get only genuine risks (not NOISE)."""
        return [r for r in self.verified_risks if r.is_risk and r.risk_level != RiskLevel.NOISE]
    
    @property
    def noise_filtered(self) -> int:
        """Count of hits filtered as noise."""
        return len([r for r in self.verified_risks if r.risk_level == RiskLevel.NOISE])
    
    @property
    def high_priority(self) -> list[VerifiedRisk]:
        """Get HIGH priority risks."""
        return [r for r in self.verified_risks if r.risk_level == RiskLevel.HIGH]
    
    @property
    def medium_priority(self) -> list[VerifiedRisk]:
        """Get MEDIUM priority risks."""
        return [r for r in self.verified_risks if r.risk_level == RiskLevel.MEDIUM]
    
    def to_json(self) -> str:
        """Export report as formatted JSON."""
        report = {
            "summary": {
                "total_analyzed": self.total_hits_analyzed,
                "genuine_risks": len(self.genuine_risks),
                "noise_filtered": self.noise_filtered,
                "high_priority": len(self.high_priority),
                "medium_priority": len(self.medium_priority),
            },
            "verified_risks": [r.to_dict() for r in self.genuine_risks],
        }
        return json.dumps(report, indent=2, ensure_ascii=False)
    
    def print_report(self) -> None:
        """Print formatted executive-level report to console."""
        print("\n" + "=" * 70)
        print("  EXECUTIVE INTELLIGENCE REPORT (AI-Analyzed)")
        print("=" * 70)
        
        print(f"\nðŸ“Š Ã–zet:")
        print(f"   Analiz edilen: {self.total_hits_analyzed}")
        print(f"   GerÃ§ek risk: {len(self.genuine_risks)}")
        print(f"   Filtrelenen: {self.noise_filtered}")
        print(f"   HIGH Ã¶ncelik: {len(self.high_priority)}")
        print(f"   MEDIUM Ã¶ncelik: {len(self.medium_priority)}")
        
        if self.high_priority:
            print("\nðŸš¨ YÃœKSEK Ã–NCELÄ°KLÄ° RÄ°SKLER:")
            print("-" * 50)
            for i, risk in enumerate(self.high_priority, 1):
                self._print_executive_risk(i, risk)
        
        if self.medium_priority:
            print("\nâš ï¸  ORTA Ã–NCELÄ°KLÄ° RÄ°SKLER:")
            print("-" * 50)
            for i, risk in enumerate(self.medium_priority, 1):
                self._print_executive_risk(i, risk)
        
        print("\n" + "=" * 70)
    
    def _print_executive_risk(self, index: int, risk: VerifiedRisk) -> None:
        """Print a single risk with all executive-level details."""
        print(f"\n{index}. [{risk.original_hit.sector.value}] Sayfa {risk.original_hit.page_number}")
        
        if risk.speaker_identified:
            print(f"   ðŸ‘¤ KonuÅŸmacÄ±: {risk.speaker_identified}")
        
        print(f"   ðŸ“‹ Ã–zet: {risk.summary}")
        
        if risk.business_impact:
            print(f"   ðŸ’° Ä°ÅŸ Etkisi: {risk.business_impact}")
        
        if risk.compliance_difficulty:
            print(f"   âš™ï¸  Uyum ZorluÄŸu: {risk.compliance_difficulty}")
        
        if risk.tone_analysis:
            print(f"   ðŸŽ­ Ton: {risk.tone_analysis}")
        
        if risk.likelihood:
            print(f"   ðŸ“ˆ Kanun OlasÄ±lÄ±ÄŸÄ±: {risk.likelihood}")
        
        print(f"   âœ… Eylem: {risk.actionable_insight}")


class GeminiAnalyst:
    """
    AI-powered risk verification using Google Gemini.
    
    Analyzes text snippets from RiskHits to determine if they represent
    genuine legislative threats or just general discussion/noise.
    
    Example:
        analyst = GeminiAnalyst(api_key="your-api-key")
        report = await analyst.analyze_hits(risk_hits)
        report.print_report()
    """
    
    # Sector-specific role descriptions for prompt engineering (Turkish)
    SECTOR_ROLES = {
        Sector.CRYPTO: "kripto para, blockchain ve dijital varlÄ±k",
        Sector.ENERGY: "enerji sektÃ¶rÃ¼, EPDK ve ÅŸebeke hizmetleri",
        Sector.CONSTRUCTION: "inÅŸaat, gayrimenkul ve kentsel dÃ¶nÃ¼ÅŸÃ¼m",
        Sector.FINTECH: "finansal teknoloji, Ã¶deme sistemleri ve bankacÄ±lÄ±k",
    }
    
    # Executive-Level Strategic Insight Prompt (Turkish)
    ANALYSIS_PROMPT = """Sen Fortune 500 ÅŸirketlerine danÄ±ÅŸmanlÄ±k yapan KÄ±demli RegÃ¼lasyon Strateji DanÄ±ÅŸmanÄ±sÄ±n.

{sector_description} sektÃ¶rÃ¼nde faaliyet gÃ¶steren bir mÃ¼ÅŸteriyi korumak iÃ§in yasama tutanaklarÄ±nÄ± analiz ediyorsun.

**GÃ–REV:** Sadece Ã¶zetleme deÄŸil, Ä°Åž ETKÄ°SÄ°NÄ° TAHMÄ°N ET.

METÄ°N:
\"\"\"
{text}
\"\"\"

BAÄžLAM:
- SektÃ¶r: {sector_name}
- Anahtar kelimeler: "{sector_keyword}", "{threat_keyword}"
- Sayfa: {page_number}
{speaker_context}

AÅžAÄžIDAKÄ° ALANLARI Ä°Ã‡EREN BÄ°R JSON DÃ–NDÃœR:

{{
  "is_risk": true veya false,
  "risk_level": "HIGH" | "MEDIUM" | "LOW" | "NOISE",
  
  "summary": "YÃ¶netici Ã¶zeti - maksimum 2 cÃ¼mle. Ne tartÄ±ÅŸÄ±lÄ±yor ve neden Ã¶nemli?",
  
  "business_impact": "KRÄ°TÄ°K: Spesifik operasyonel veya finansal sonuÃ§larÄ± aÃ§Ä±kla. Ã–rnek: 'Yeni uyum ekipleri gerektirerek OPEX'i %15 artÄ±rÄ±r', 'Engelleme nedeniyle %5 gelir kaybÄ± riski', 'Lisans iptali riski'",
  
  "compliance_difficulty": "Hard" | "Medium" | "Easy" - Bu dÃ¼zenlemeye uyum saÄŸlamak ne kadar zor?
  
  "actionable_insight": "Hukuk ve ÃœrÃ¼n ekipleri iÃ§in adÄ±m adÄ±m Ã¶neri. Ã–rnek: '1. Hukuk ekibini bilgilendir, 2. SektÃ¶r derneÄŸiyle lobi koordinasyonu yap, 3. Alternatif iÅŸ modeli hazÄ±rla'",
  
  "tone_analysis": "Hostile" | "Neutral" | "Supportive" - KonuÅŸmacÄ± sektÃ¶re karÅŸÄ± dÃ¼ÅŸmanca mÄ±, tarafsÄ±z mÄ± yoksa destekleyici mi?
  
  "likelihood": "High" | "Low" - KonuÅŸmacÄ±nÄ±n otoritesine gÃ¶re kanun olma olasÄ±lÄ±ÄŸÄ±. Bakan/BaÅŸkan = High, Muhalefet = Low
  
  "speaker_identified": "Tespit edilen konuÅŸmacÄ± ve rolÃ¼. Ã–rnek: 'Mehmet MUÅž (BAÅžKAN, Samsun)', 'Bilinmiyor'"
}}

DEÄžERLENDÄ°RME KRÄ°TERLERÄ°:

RÄ°SK SEVÄ°YESÄ°:
- HIGH: Oylama aÅŸamasÄ±nda, ceza miktarlarÄ± belirtilmiÅŸ, BAÅžKAN/VEKÄ°L tarafÄ±ndan destekleniyor
- MEDIUM: Aktif tartÄ±ÅŸmada, komisyon Ã¼yelerinden destek var
- LOW: Erken aÅŸama, sadece soru veya endiÅŸe dile getiriliyor
- NOISE: GerÃ§ek risk yok, geÃ§miÅŸ olaylar veya genel sohbet

KONUÅžMACI OTORÄ°TESÄ°:
- BAÅžKAN â†’ Ã‡ok yÃ¼ksek etki, kanun olasÄ±lÄ±ÄŸÄ± HIGH
- BAÅžKANVEKÄ°LÄ° â†’ YÃ¼ksek etki
- BAKAN â†’ Ã‡ok yÃ¼ksek etki, hÃ¼kÃ¼met politikasÄ±
- ÃœYE (Ä°ktidar partisi) â†’ Orta-yÃ¼ksek etki  
- ÃœYE (Muhalefet) â†’ DÃ¼ÅŸÃ¼k etki, kanun olasÄ±lÄ±ÄŸÄ± LOW
- Bilinmeyen â†’ Ä°Ã§erik bazlÄ± deÄŸerlendir

SADECE JSON nesnesiyle yanÄ±t ver. Markdown veya ek aÃ§Ä±klama ekleme."""

    # Pattern to extract speaker names from Turkish parliamentary transcripts
    # Format: "ADI SOYADI (Åžehir)" or "BAÅžKAN ADI SOYADI"
    SPEAKER_PATTERN = re.compile(
        r'(?:BAÅžKAN\s+)?([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+(?:\s+[A-ZÃ‡ÄžÄ°Ã–ÅžÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+)*\s+[A-ZÃ‡ÄžÄ°Ã–ÅžÃœ]+)\s*(?:\(([^)]+)\))?',
        re.UNICODE
    )

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = "gemini-2.0-flash",
    ) -> None:
        """
        Initialize the Gemini analyst.
        
        Args:
            api_key: Google Gemini API key (or set REGUSENSE_GEMINI_API_KEY env var)
            model: Gemini model to use (default: gemini-2.0-flash)
        """
        if genai is None:
            raise ImportError(
                "google-generativeai package not installed. "
                "Run: pip install google-generativeai"
            )
        
        self.api_key = api_key or os.environ.get("REGUSENSE_GEMINI_API_KEY") or os.environ.get("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError(
                "Gemini API key required. Set REGUSENSE_GEMINI_API_KEY or GEMINI_API_KEY environment variable, "
                "or pass api_key parameter."
            )
        
        self.model_name = model
        
        # Configure the API
        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel(self.model_name)
        
        # Load commission members database
        self.members_db = self._load_members_database()
        
        logger.info(f"GeminiAnalyst initialized with model: {self.model_name}")
        if self.members_db:
            total_members = sum(len(members) for members in self.members_db.values())
            logger.info(f"Loaded {total_members} commission members from {len(self.members_db)} commissions")
    
    def _load_members_database(self) -> dict:
        """Load commission members from JSON file."""
        # Try multiple possible locations
        possible_paths = [
            Path(__file__).parent.parent / "data" / "commission_members.json",
            Path("data/commission_members.json"),
        ]
        
        for path in possible_paths:
            if path.exists():
                try:
                    with open(path, "r", encoding="utf-8") as f:
                        data = json.load(f)
                    logger.info(f"Loaded commission members from: {path}")
                    return data
                except Exception as e:
                    logger.warning(f"Failed to load members from {path}: {e}")
        
        logger.warning("Commission members database not found - speaker identification disabled")
        return {}
    
    def _extract_speakers_from_text(self, text: str) -> list[dict]:
        """
        Extract speaker names and their constituencies from text.
        
        Returns list of dicts with 'name' and 'constituency' keys.
        """
        speakers = []
        seen = set()
        
        for match in self.SPEAKER_PATTERN.finditer(text):
            name = match.group(1).strip()
            constituency = match.group(2).strip() if match.group(2) else None
            
            # Normalize the name
            normalized = self._normalize_name(name)
            
            if normalized and normalized not in seen:
                seen.add(normalized)
                speakers.append({
                    "name": name,
                    "normalized_name": normalized,
                    "constituency": constituency,
                })
        
        return speakers
    
    def _normalize_name(self, name: str) -> str:
        """Normalize a name for comparison."""
        # Remove extra spaces and normalize Turkish characters
        name = " ".join(name.split())
        return name.upper()
    
    def _lookup_member(self, name: str, constituency: Optional[str] = None) -> Optional[dict]:
        """
        Look up a member in the database by name and optionally constituency.
        
        Returns member dict with role if found, None otherwise.
        """
        if not self.members_db:
            return None
        
        normalized_name = self._normalize_name(name)
        
        for commission_name, members in self.members_db.items():
            for member in members:
                member_normalized = self._normalize_name(member["name"])
                
                # Check if names match (allow partial match for common variations)
                if (member_normalized == normalized_name or 
                    normalized_name in member_normalized or 
                    member_normalized in normalized_name):
                    
                    # If constituency is provided, verify it matches
                    if constituency and member.get("constituency"):
                        if constituency.lower() != member["constituency"].lower():
                            continue
                    
                    return {
                        "name": member["name"],
                        "role": member["role"],
                        "constituency": member.get("constituency"),
                        "commission": commission_name,
                    }
        
        return None
    
    def _get_speaker_context(self, hit: RiskHit) -> str:
        """
        Extract and format speaker context from the hit text.
        
        Returns a formatted string describing who is speaking and their role.
        """
        text = hit.expanded_context if hit.expanded_context else hit.snippet
        speakers = self._extract_speakers_from_text(text)
        
        if not speakers:
            return ""
        
        speaker_info_list = []
        for speaker in speakers[:3]:  # Limit to first 3 speakers
            member = self._lookup_member(speaker["name"], speaker.get("constituency"))
            if member:
                role_weight = self._get_role_weight(member["role"])
                speaker_info_list.append(
                    f"- {member['name']} ({member['role']}, {member.get('constituency', 'N/A')}) "
                    f"[AÄŸÄ±rlÄ±k: {role_weight}]"
                )
            else:
                speaker_info_list.append(f"- {speaker['name']} (Rol bilinmiyor)")
        
        if speaker_info_list:
            return "\n".join(speaker_info_list)
        return ""
    
    def _get_role_weight(self, role: str) -> str:
        """Get the weight/importance of a role for risk assessment."""
        role_weights = {
            "BAÅžKAN": "Ã‡OK YÃœKSEK - Komisyon baÅŸkanÄ±nÄ±n aÃ§Ä±klamalarÄ± yasa iÃ§in kritik",
            "BAÅžKANVEKÄ°LÄ°": "YÃœKSEK - BaÅŸkanvekili yetkili konuÅŸmacÄ±",
            "SÃ–ZCÃœ": "ORTA-YÃœKSEK - Komisyon sÃ¶zcÃ¼sÃ¼ resmi gÃ¶rÃ¼ÅŸleri aktarÄ±r",
            "KATÄ°P": "ORTA - ProsedÃ¼rel rol",
            "ÃœYE": "ORTA - Komisyon Ã¼yesi tartÄ±ÅŸmaya katÄ±lÄ±r",
        }
        return role_weights.get(role, "BÄ°LÄ°NMÄ°YOR")
    
    def _build_prompt(self, hit: RiskHit) -> str:
        """Build the analysis prompt for a specific hit, including speaker context."""
        sector_desc = self.SECTOR_ROLES.get(
            hit.sector, 
            f"{hit.sector.value.lower()} sector regulations"
        )
        
        # Use expanded context if available, otherwise fall back to snippet
        text = hit.expanded_context if hit.expanded_context else hit.snippet
        
        # Extract speaker context from the text
        speaker_context = self._get_speaker_context(hit)
        if speaker_context:
            speaker_section = f"\n\nTESPÄ°T EDÄ°LEN KONUÅžMACILAR:\n{speaker_context}"
        else:
            speaker_section = "\n\nKONUÅžMACI: Tespit edilemedi"
        
        return self.ANALYSIS_PROMPT.format(
            sector_description=sector_desc,
            sector_name=hit.sector.value,
            text=text,
            sector_keyword=hit.sector_keyword,
            threat_keyword=hit.threat_keyword,
            page_number=hit.page_number,
            speaker_context=speaker_section,
        )
    
    def _parse_response(self, response_text: str, hit: RiskHit) -> VerifiedRisk:
        """Parse Gemini response into VerifiedRisk object."""
        try:
            # Clean up the response (remove markdown code blocks if present)
            cleaned = response_text.strip()
            if cleaned.startswith("```json"):
                cleaned = cleaned[7:]
            if cleaned.startswith("```"):
                cleaned = cleaned[3:]
            if cleaned.endswith("```"):
                cleaned = cleaned[:-3]
            cleaned = cleaned.strip()
            
            # Parse JSON
            data = json.loads(cleaned)
            
            # Map risk level
            risk_level_str = data.get("risk_level", "NOISE").upper()
            try:
                risk_level = RiskLevel(risk_level_str)
            except ValueError:
                risk_level = RiskLevel.NOISE
            
            return VerifiedRisk(
                original_hit=hit,
                is_risk=data.get("is_risk", False),
                risk_level=risk_level,
                summary=data.get("summary", ""),
                business_impact=data.get("business_impact", ""),
                compliance_difficulty=data.get("compliance_difficulty", ""),
                actionable_insight=data.get("actionable_insight", ""),
                tone_analysis=data.get("tone_analysis", ""),
                likelihood=data.get("likelihood", ""),
                speaker_identified=data.get("speaker_identified", ""),
                raw_response=data,
            )
            
        except json.JSONDecodeError as e:
            logger.warning(f"Failed to parse Gemini response: {e}")
            logger.debug(f"Raw response: {response_text}")
            return VerifiedRisk(
                original_hit=hit,
                is_risk=False,
                risk_level=RiskLevel.NOISE,
                summary="Failed to analyze",
                actionable_insight="Manual review recommended",
                raw_response={"error": str(e), "raw": response_text},
            )
    
    def analyze_hit(self, hit: RiskHit) -> VerifiedRisk:
        """
        Analyze a single risk hit using Gemini.
        
        Args:
            hit: RiskHit to analyze
            
        Returns:
            VerifiedRisk with AI classification
        """
        prompt = self._build_prompt(hit)
        
        try:
            response = self.model.generate_content(prompt)
            result = self._parse_response(response.text, hit)
            
            logger.debug(
                f"Analyzed hit on page {hit.page_number}: "
                f"{result.risk_level.value} - {result.summary[:50]}..."
            )
            
            return result
            
        except Exception as e:
            logger.error(f"Gemini API error for hit on page {hit.page_number}: {e}")
            return VerifiedRisk(
                original_hit=hit,
                is_risk=False,
                risk_level=RiskLevel.NOISE,
                summary=f"API error: {str(e)[:100]}",
                actionable_insight="Manual review recommended",
                raw_response={"error": str(e)},
            )
    
    def analyze_hits(self, hits: list[RiskHit]) -> IntelligenceReport:
        """
        Analyze multiple risk hits and generate an intelligence report.
        
        Args:
            hits: List of RiskHits to analyze
            
        Returns:
            IntelligenceReport with all verified risks
        """
        report = IntelligenceReport(total_hits_analyzed=len(hits))
        
        logger.info(f"Starting AI analysis of {len(hits)} hits...")
        
        for i, hit in enumerate(hits, 1):
            logger.info(f"Analyzing hit {i}/{len(hits)}: Page {hit.page_number} [{hit.sector.value}]")
            
            verified = self.analyze_hit(hit)
            report.verified_risks.append(verified)
            
            # Log progress
            if verified.is_risk and verified.risk_level != RiskLevel.NOISE:
                logger.info(f"  â†’ {verified.risk_level.value}: {verified.summary[:60]}...")
            else:
                logger.info(f"  â†’ NOISE (filtered)")
        
        logger.info(
            f"Analysis complete: {len(report.genuine_risks)} genuine risks, "
            f"{report.noise_filtered} noise filtered"
        )
        
        return report


# Convenience function for quick analysis
def verify_risks(hits: list[RiskHit], api_key: Optional[str] = None) -> IntelligenceReport:
    """
    Convenience function to verify risk hits using Gemini AI.
    
    Args:
        hits: List of RiskHits from RiskEngine
        api_key: Optional Gemini API key
        
    Returns:
        IntelligenceReport with verified risks
    """
    analyst = GeminiAnalyst(api_key=api_key)
    return analyst.analyze_hits(hits)
